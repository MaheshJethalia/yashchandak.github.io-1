<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-12-02T22:36:30-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Yash Chandak</title><subtitle>y[lastname]@cs.umass.edu</subtitle><author><name>Yash Chandak</name></author><entry><title type="html">Towards Safe Policy Improvement for Non-Stationary MDPs</title><link href="http://localhost:4000/blog/spin" rel="alternate" type="text/html" title="Towards Safe Policy Improvement for Non-Stationary MDPs" /><published>2020-10-19T00:00:00-04:00</published><updated>2020-10-19T00:00:00-04:00</updated><id>http://localhost:4000/blog/SPIN</id><content type="html" xml:base="http://localhost:4000/blog/spin">&lt;div class=&quot;message&quot;&gt;
 This post is based on a NeurIPS 2020 paper that I worked on with &lt;a href=&quot;&quot;&gt; Scott Jordan&lt;/a&gt;, &lt;a href=&quot;https://research.adobe.com/person/georgios-theocharous/&quot;&gt; Georgios Theocharous&lt;/a&gt;, &lt;a href=&quot;https://webdocs.cs.ualberta.ca/~whitem/&quot;&gt;Martha White&lt;/a&gt;, and &lt;a href=&quot;https://people.cs.umass.edu/~pthomas/&quot;&gt;Philip Thomas&lt;/a&gt;. Here are the links for the &lt;a href=&quot;https://arxiv.org/abs/2010.12645&quot;&gt; paper&lt;/a&gt; and the &lt;a href=&quot;https://github.com/ScottJordan/SafePolicyImprovementNonstationary&quot;&gt;code&lt;/a&gt;.
&lt;/div&gt;

&lt;h2 id=&quot;motivation-and-probelm&quot;&gt;Motivation and probelm&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Example scenarios&lt;/li&gt;
  &lt;li&gt;Ask the two main questions&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;forecasting&quot;&gt;Forecasting&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Compare stationary and non-stationary (Two new images)&lt;/li&gt;
  &lt;li&gt;Generlizing thes tatioanry setting&lt;/li&gt;
  &lt;li&gt;Raise the question that will lead to off-policy&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/images/blog/spin/SafeNSRLidea.png&quot; alt=&quot;idea&quot; style=&quot;width: 65%; border-radius:0%&quot; /&gt;
 &lt;/p&gt;

&lt;h2 id=&quot;overall-methodology&quot;&gt;Overall methodology&lt;/h2&gt;

&lt;p&gt;something something&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
     &lt;img src=&quot;/images/blog/spin/SafeNSRL.png&quot; alt=&quot;seldonian&quot; style=&quot;vertical-align:middle; width: 65%; margin:0px 10px; border-radius:0%&quot; /&gt;
     &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Forecasting (add image)&lt;/li&gt;
  &lt;li&gt;Gradient computation&lt;/li&gt;
  &lt;li&gt;benefits&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;searching-for-a-candidate-policy&quot;&gt;Searching for a candidate policy&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;
     &lt;img src=&quot;/images/blog/spin/diffLB.png&quot; alt=&quot;candidate&quot; style=&quot;vertical-align:middle; width: 70%; margin:0px 10px; border-radius:0%&quot; /&gt;
     &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Discuss&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;empirical-performance&quot;&gt;Empirical performance&lt;/h2&gt;

&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/images/blog/spin/results.png&quot; alt=&quot;results&quot; style=&quot;vertical-align:middle; width: 60%; margin:0px 10px; border-radius:0%&quot; /&gt;
 &lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Plots and results&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;open-questions&quot;&gt;Open questions&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Discuss variance reduction briefly&lt;/li&gt;
  &lt;li&gt;Better off-policy methods OPE&lt;/li&gt;
  &lt;li&gt;Better Time-series methods&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cum sociis natoque penatibus et magnis &lt;a href=&quot;#&quot;&gt;dis parturient montes&lt;/a&gt;, nascetur ridiculus mus. &lt;em&gt;Aenean eu leo quam.&lt;/em&gt; Pellentesque ornare sem lacinia quam venenatis vestibulum. Sed posuere consectetur est at lobortis. Cras mattis consectetur purus sit amet fermentum.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Curabitur blandit tempus porttitor. Nullam quis risus eget urna mollis ornare vel eu leo. Nullam id dolor id nibh ultricies vehicula ut id elit.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Etiam porta &lt;strong&gt;sem malesuada magna&lt;/strong&gt; mollis euismod. Cras mattis consectetur purus sit amet fermentum. Aenean lacinia bibendum nulla sed consectetur.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
  &amp; \phi(x,y) = \phi \left(\sum_{i=1}^n x_ie_i, \sum_{j=1}^n y_je_j \right)
  = \sum_{i=1}^n \sum_{j=1}^n x_i y_j \phi(e_i, e_j) = \\
  &amp; (x_1, \ldots, x_n) \left( \begin{array}{ccc}
      \phi(e_1, e_1) &amp; \cdots &amp; \phi(e_1, e_n) \\
      \vdots &amp; \ddots &amp; \vdots \\
      \phi(e_n, e_1) &amp; \cdots &amp; \phi(e_n, e_n)
    \end{array} \right)
  \left( \begin{array}{c}
      y_1 \\
      \vdots \\
      y_n
    \end{array} \right)
\end{align*} %]]&gt;&lt;/script&gt;</content><author><name>Yash Chandak</name></author><category term="timeseries" /><category term="nonstationary" /><category term="reinforcement" /><category term="safety" /><category term="bootstrap" /><summary type="html">How do we create model-free algorithms that can search for a good policy in a non-stationary MDP?</summary></entry><entry><title type="html">Optimizing for the Future in Non-Stationary MDPs</title><link href="http://localhost:4000/blog/prognosticator" rel="alternate" type="text/html" title="Optimizing for the Future in Non-Stationary MDPs" /><published>2020-08-19T00:00:00-04:00</published><updated>2020-08-19T00:00:00-04:00</updated><id>http://localhost:4000/blog/OptFuture</id><content type="html" xml:base="http://localhost:4000/blog/prognosticator">&lt;div class=&quot;message&quot;&gt;
  This post is based on an ICML 2020 paper that I worked on with &lt;a href=&quot;https://research.adobe.com/person/georgios-theocharous/&quot;&gt; Georgios Theocharous &lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/citations?user=yK56jugAAAAJ&amp;amp;hl=en&quot;&gt;Shiv Shankar&lt;/a&gt;, &lt;a href=&quot;https://webdocs.cs.ualberta.ca/~whitem/&quot;&gt;Martha White&lt;/a&gt;, &lt;a href=&quot;https://people.cs.umass.edu/~mahadeva/Site/About_Me.html&quot;&gt;Sridhar Mahadevan&lt;/a&gt;, and &lt;a href=&quot;https://people.cs.umass.edu/~pthomas/&quot;&gt;Philip Thomas&lt;/a&gt;. Here are the links for the &lt;a href=&quot;https://arxiv.org/abs/2005.08158&quot;&gt; paper &lt;/a&gt;  and the &lt;a href=&quot;https://github.com/yashchandak/OptFuture_NSMDP&quot;&gt; code&lt;/a&gt;.
&lt;/div&gt;

&lt;p&gt;Reinforcement learning algorithms typically assume that the transition dynamics and reward functions are fixed, that is the underlying MDP is &lt;em&gt;stationary&lt;/em&gt;. This assumption is often violated in many practical problems of interest. For example, consider an assistive driving system. Over time, tires gradually suffer from wear and tear, leading to increased friction. Similarly, in almost all human-computer interaction applications, e.g., automated medical care, dialogue systems, and marketing, human behavior gradually changes over time. In such scenarios, if the automated system is not adapted to take such changes into account then the system might quickly become sub-optimal.
 This raises our main question: how do we build systems that &lt;em&gt;proactively&lt;/em&gt; search for a policy that will be good for the future MDP?&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;In this work, we merge ideas from model-free reinforcement learning and time-series literature to develop a method that&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Concisely models the effect of changes in the environment on a policy’s performance using a &lt;em&gt;univariate&lt;/em&gt; time-series.&lt;/li&gt;
  &lt;li&gt;Does not require modeling the transition and reward functions.&lt;/li&gt;
  &lt;li&gt;Can leverage all the past data and is data-efficient.&lt;/li&gt;
  &lt;li&gt;Mitigates performance lag by proactively optimizing performance for future episodes.&lt;/li&gt;
  &lt;li&gt;It degenerates to an estimator of the ordinary policy gradient if the system is stationary.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, our method is designed for environments where changes are smooth and gradual, and might not be ideal for environments where the changes are abrupt.&lt;/p&gt;

&lt;h2 id=&quot;a-time-series-perspective&quot;&gt;A time-series perspective&lt;/h2&gt;

&lt;p&gt;It would have been ideal if we had some samples from the future MDP, so that we could search for a policy &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt; before hand, which would be good for the MDP the agent faces when deployed. However, getting even a single data sample from future MDP is impossible. All that we can expect is some data collected using a behavior policy &lt;script type=&quot;math/tex&quot;&gt;\beta&lt;/script&gt; for the MDPs the agent interacted with in the past episodes. 
  Therefore, to estimate the future performance of a policy &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt; we use an indirect procedure by first asking a counter-factual question:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;What would have been &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;’s performances, if we had executed &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt; in the past episodes?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This can be easily answered using off-policy performance estimation. Let the subscripts denote the episode number and superscripts denote the timestep within an epsiode, then an unbiased estimate of the performance of &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt; in the &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;‘th episode is given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
     \hat J_i(\pi) &amp;:=  \sum_{t=0}^{H} \left ( \prod_{l=0}^t 
    \frac{\pi(A_i^l|S_i^l)}{\beta_i(A_i^l|S_i^l)} \right) \gamma^t R_i^t. \label{eqn:ope}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Having obtained the counter-factual estimate of &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;’s performances in the past episodes we now ask the other question,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;’s performance in the past episodes are known, can we forecast &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;’s future performance?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Indeed, since &lt;script type=&quot;math/tex&quot;&gt;\forall i, \,\, \hat J_i(\pi)&lt;/script&gt; is an unbiased estiamtes of &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;’s counter-factual performance, these estimates can be analyzed to understand how &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;’s performance has been changing due to the underlying non-stationarity. Therefore, a simple curve-fitting can now be performed on the counter-factual performance estimates to reveal the performance trend over time, using which we can forecast the future performance for &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
 &lt;img src=&quot;/images/blog/optfuture/Eval.png&quot; alt=&quot;eval&quot; style=&quot;width: 30%;  margin:20px 20px; border-radius:0%&quot; /&gt;
 &lt;/p&gt;

&lt;p&gt;The above images illustrate the key idea. Since the performance of &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt; is constant across episodes in a stationary environment, off-policy evaluation provides a noisy estimate about a constant value for &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;’s past performances. In comparison, in the non-stationary setting, off-policy evaluation provides a noisy estimate about a time-varying value for &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;’s past performances. Therefore, &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;’s performance once episode into the future &lt;script type=&quot;math/tex&quot;&gt;J_{k+1}(\theta)&lt;/script&gt; can now be forecasted using a time series function &lt;script type=&quot;math/tex&quot;&gt;\Psi&lt;/script&gt; that takes as input the counter-factual performance estimates for the past episodes,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
    \hat J_{k+1}(\theta) :=  \Psi (\hat J_1(\pi), \hat J_2(\pi), ...., \hat J_k(\pi)). \label{eqn:forecaster}
\end{align}&lt;/script&gt;

&lt;p&gt;Here is a simple example using least-squares regression. Let &lt;script type=&quot;math/tex&quot;&gt;X := [1, 2, ..., k]^\top \in \mathbb{R}^{k \times 1}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y := [\hat J_1(\pi), \hat J_2(\pi), \hat J_2(\pi), ..., \hat J_k(\pi)]^\top  \in \mathbb{R}^{k \times 1}&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; is the number for the last episode observed. Since performance trends need not be linear, let &lt;script type=&quot;math/tex&quot;&gt;\phi(x) \in \mathbb{R}^{1 \times d}&lt;/script&gt; denote a &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;-dimensional basis function (e.g., Fourier basis) for encoding the time index, and &lt;script type=&quot;math/tex&quot;&gt;\Phi&lt;/script&gt; be the corresponding basis matrix, such that non-linear performance trends can be captured. Then an estimate of &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt;’s performance can be estiamted as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
   \hat J_{k+1}(\pi) =  \phi(k+1)(\Phi^\top  \Phi)^{-1}\Phi^\top Y.
\end{align}&lt;/script&gt;

&lt;p&gt;Note that this approach naturally generalizes for the stationary setting as well, where the time series trend corresponds to a horizontal line.&lt;/p&gt;

&lt;h2 id=&quot;optimizing-the-future-performance&quot;&gt;Optimizing the future performance&lt;/h2&gt;

&lt;p&gt;Using the time-series perspective, we saw how future performance of a given policy &lt;script type=&quot;math/tex&quot;&gt;\pi&lt;/script&gt; can be estimated. Now, to search for a policy that would maximize the future performance, we take the perspective of differentiable programming and treat &lt;em&gt;least-squares regression as a differentiable operator&lt;/em&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
     &lt;img src=&quot;/images/blog/optfuture/idea.png&quot; alt=&quot;idea&quot; style=&quot;vertical-align:middle; width: 30%; margin:20px 20px; border-radius:0%&quot; /&gt;
     &lt;/p&gt;

&lt;p&gt;The above image illustrates the main idea. The dotted lines represent that we cannot use conventional methods to compute or estimate gradients of &lt;script type=&quot;math/tex&quot;&gt;\hat J_{k+1}(\theta)&lt;/script&gt; as we have no samples from the future MDP. Instead, we estimate &lt;script type=&quot;math/tex&quot;&gt;J_{k+1}(\theta)&lt;/script&gt; as a composition of two programs: one which connects the policy’s parameters to its past performances, and the other which forecasts future performance as a function of these past performances. An optimization procedure can be  obtained by taking derivatives through this composition of programs to update policy parameters in a direction that maximizes future performance.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
    \frac{ d \hat J_{k+1}(\theta)}{d \theta} &amp;= \frac{d \Psi(\hat J_1(\theta), ..., \hat J_k(\theta))}{d \theta} \\
    %
    &amp;= \sum_{i=1}^k \underbrace{ \frac{\partial \Psi(\hat J_1(\theta), ..., \hat J_k(\theta))}{\partial \hat J_i(\theta)}}_{\text{(a)}}\cdot \underbrace{ \frac{d \hat J_i(\theta)}{d \theta}}_{(b)}. \,\,\, 
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;This decomposition has an elegant intuitive interpretation. The terms assigned to &lt;script type=&quot;math/tex&quot;&gt;(a)&lt;/script&gt; correspond to how the future prediction would change as a function of past outcomes, and the terms in &lt;script type=&quot;math/tex&quot;&gt;(b)&lt;/script&gt; indicate how the past outcomes would change due to changes in the parameters of the policy &lt;script type=&quot;math/tex&quot;&gt;\pi^\theta&lt;/script&gt;. Notice that term (b) can be obtained using standard off-policy gradient estimators and term (a) can be obtained as the following,&lt;/p&gt;

&lt;p&gt;\begin{align}
    \frac{\partial \hat J_{k+1}(\theta)}{\partial \hat J_i(\theta)}  &amp;amp;= \frac{\partial \phi(k+1)(\Phi^\top  \Phi)^{-1}\Phi^\top  Y}{\partial Y_i} &lt;br /&gt;
    %
    = [ \phi(k+1)(\Phi^\top  \Phi)^{-1}\Phi^\top  ]_i.
\end{align}&lt;/p&gt;

&lt;h2 id=&quot;an-intriguing-behavior&quot;&gt;An intriguing behavior&lt;/h2&gt;

&lt;p&gt;Notice that as the scalar term (a) is multiplied by the off-policy gradient term (b), the gradient &lt;script type=&quot;math/tex&quot;&gt;d \hat J_{k+1}(\theta)/d \theta&lt;/script&gt; can be viewed as a weighted sum of off-policy policy gradients. In the following figure, we provide a visualization for the weights obtained from term (a) for different episodes &lt;script type=&quot;math/tex&quot;&gt;i \in [1, 100]&lt;/script&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
     &lt;img align=&quot;left&quot; src=&quot;/images/blog/optfuture/weights.png&quot; alt=&quot;idea&quot; style=&quot;width: 30%; margin:10px 20px; border-radius:0%&quot; /&gt;
 &lt;img src=&quot;/images/blog/optfuture/Eval.png&quot; alt=&quot;Eval&quot; style=&quot;width: 40%;margin:20px 30px; border-radius:0%&quot; /&gt;
     &lt;/p&gt;

&lt;p&gt;When an identity basis or Fourier basis is used for &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt; we notice an occurrence of negative weights, suggesting that the optimization procedure should move towards a policy that had &lt;em&gt;lower&lt;/em&gt; performance in some of the past episodes!&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;While this negative weighting seems unusual at first glance, it has an intriguing interpretation.  Consider the image on the right above. 
Despite having lower estimates of return &lt;em&gt;everywhere&lt;/em&gt;, &lt;script type=&quot;math/tex&quot;&gt;\pi_2&lt;/script&gt;’s rising trend suggests that it might have higher performance in the future, that is, &lt;script type=&quot;math/tex&quot;&gt;J_{k+1}(\pi_2) &gt; J_{k+1}(\pi_1)&lt;/script&gt;.
Existing online learning methods like follow-the-leader maximize performance on all the past data uniformly (green curve). 
Similarly, the exponential weights (red curve) are representative of approaches that only optimize using data from recent episodes and discard previous data.
Either of these methods that use only non-negative weights cannot capture the trend to forecast &lt;script type=&quot;math/tex&quot;&gt;J_{k+1}(\pi_2) &gt; J_{k+1}(\pi_1)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt; 
However, the weights obtained when using the identity basis would facilitate &lt;em&gt;minimization&lt;/em&gt; of performances in the distant past and maximization of performance in the recent past.
Intuitively, this means that it moves towards a policy whose performance is on a &lt;em&gt;linear rise&lt;/em&gt;, as it expects that policy to have better performance in the future. Fourier basis further extends this idea while removing the restriction on the trend to be linear. 
Observe the alternating sign of weights in the figure abvoe when using the Fourier basis.
This suggests that the optimization procedure will take into account the &lt;em&gt;sequential differences&lt;/em&gt; in performances over the past, thereby favoring the policy that has shown the most performance increments in the past.&lt;/p&gt;

&lt;h3 id=&quot;open-questions&quot;&gt;Open questions&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Discuss variance reduction briefly&lt;/li&gt;
  &lt;li&gt;Better off-policy methods OPE&lt;/li&gt;
  &lt;li&gt;Better Time-series methods&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Yash Chandak</name></author><category term="timeseries" /><category term="nonstationary" /><category term="reinforcement" /><summary type="html">How do we create model-free algorithms that can search for a good policy in a non-stationary MDP?</summary></entry><entry><title type="html">Hello World!</title><link href="http://localhost:4000/blog/2020/07/10/example.html" rel="alternate" type="text/html" title="Hello World!" /><published>2020-07-10T00:00:00-04:00</published><updated>2020-07-10T00:00:00-04:00</updated><id>http://localhost:4000/blog/2020/07/10/example</id><content type="html" xml:base="http://localhost:4000/blog/2020/07/10/example.html">&lt;div class=&quot;message&quot;&gt;
  This is a demo post.
&lt;/div&gt;

&lt;p&gt;Cum sociis natoque penatibus et magnis &lt;a href=&quot;#&quot;&gt;dis parturient montes&lt;/a&gt;, nascetur ridiculus mus. &lt;em&gt;Aenean eu leo quam.&lt;/em&gt; Pellentesque ornare sem lacinia quam venenatis vestibulum. Sed posuere consectetur est at lobortis. Cras mattis consectetur purus sit amet fermentum.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Curabitur blandit tempus porttitor. Nullam quis risus eget urna mollis ornare vel eu leo. Nullam id dolor id nibh ultricies vehicula ut id elit.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Etiam porta &lt;strong&gt;sem malesuada magna&lt;/strong&gt; mollis euismod. Cras mattis consectetur purus sit amet fermentum. Aenean lacinia bibendum nulla sed consectetur.&lt;/p&gt;

&lt;h2 id=&quot;inline-html-elements&quot;&gt;Inline HTML elements&lt;/h2&gt;

&lt;p&gt;HTML defines a long list of available inline tags, a complete list of which can be found on the &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/HTML/Element&quot;&gt;Mozilla Developer Network&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;To bold text&lt;/strong&gt;, use &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;strong&amp;gt;&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;To italicize text&lt;/em&gt;, use &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;em&amp;gt;&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Abbreviations, like &lt;abbr title=&quot;HyperText Markup Langage&quot;&gt;HTML&lt;/abbr&gt; should use &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;abbr&amp;gt;&lt;/code&gt;, with an optional &lt;code class=&quot;highlighter-rouge&quot;&gt;title&lt;/code&gt; attribute for the full phrase.&lt;/li&gt;
  &lt;li&gt;Citations, like &lt;cite&gt;— Mark otto&lt;/cite&gt;, should use &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;cite&amp;gt;&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;del&gt;Deleted&lt;/del&gt; text should use &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;del&amp;gt;&lt;/code&gt; and &lt;ins&gt;inserted&lt;/ins&gt; text should use &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;ins&amp;gt;&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Superscript &lt;sup&gt;text&lt;/sup&gt; uses &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;sup&amp;gt;&lt;/code&gt; and subscript &lt;sub&gt;text&lt;/sub&gt; uses &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;sub&amp;gt;&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most of these elements are styled by browsers with few modifications on our part.&lt;/p&gt;

&lt;h2 id=&quot;heading&quot;&gt;Heading&lt;/h2&gt;

&lt;p&gt;Vivamus sagittis lacus vel augue rutrum faucibus dolor auctor. Duis mollis, est non commodo luctus, nisi erat porttitor ligula, eget lacinia odio sem nec elit. Morbi leo risus, porta ac consectetur ac, vestibulum at eros.&lt;/p&gt;

&lt;h3 id=&quot;code&quot;&gt;Code&lt;/h3&gt;

&lt;p&gt;Cum sociis natoque penatibus et magnis dis &lt;code class=&quot;highlighter-rouge&quot;&gt;code element&lt;/code&gt; montes, nascetur ridiculus mus.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-js&quot; data-lang=&quot;js&quot;&gt;&lt;span class=&quot;c1&quot;&gt;// Example can be run directly in your JavaScript console
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Create a function that takes two arguments and returns the sum of those arguments
&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;adder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;b&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;return a + b&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// Call the function
&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;adder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// &amp;gt; 8&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Aenean lacinia bibendum nulla sed consectetur. Etiam porta sem malesuada magna mollis euismod. Fusce dapibus, tellus ac cursus commodo, tortor mauris condimentum nibh, ut fermentum massa.&lt;/p&gt;

&lt;h3 id=&quot;gists-via-github-pages&quot;&gt;Gists via GitHub Pages&lt;/h3&gt;

&lt;p&gt;Vestibulum id ligula porta felis euismod semper. Nullam quis risus eget urna mollis ornare vel eu leo. Donec sed odio dui.&lt;/p&gt;

&lt;noscript&gt;&lt;pre&gt;400: Invalid request&lt;/pre&gt;&lt;/noscript&gt;
&lt;script src=&quot;https://gist.github.com/5555251.js?file=gist.md&quot;&gt; &lt;/script&gt;

&lt;p&gt;Aenean eu leo quam. Pellentesque ornare sem lacinia quam venenatis vestibulum. Nullam quis risus eget urna mollis ornare vel eu leo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Donec sed odio dui. Vestibulum id ligula porta felis euismod semper.&lt;/p&gt;

&lt;h3 id=&quot;lists&quot;&gt;Lists&lt;/h3&gt;

&lt;p&gt;Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Aenean lacinia bibendum nulla sed consectetur. Etiam porta sem malesuada magna mollis euismod. Fusce dapibus, tellus ac cursus commodo, tortor mauris condimentum nibh, ut fermentum massa justo sit amet risus.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Praesent commodo cursus magna, vel scelerisque nisl consectetur et.&lt;/li&gt;
  &lt;li&gt;Donec id elit non mi porta gravida at eget metus.&lt;/li&gt;
  &lt;li&gt;Nulla vitae elit libero, a pharetra augue.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Donec ullamcorper nulla non metus auctor fringilla. Nulla vitae elit libero, a pharetra augue.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Vestibulum id ligula porta felis euismod semper.&lt;/li&gt;
  &lt;li&gt;Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.&lt;/li&gt;
  &lt;li&gt;Maecenas sed diam eget risus varius blandit sit amet non magna.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Cras mattis consectetur purus sit amet fermentum. Sed posuere consectetur est at lobortis.&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;HyperText Markup Language (HTML)&lt;/dt&gt;
  &lt;dd&gt;The language used to describe and define the content of a Web page&lt;/dd&gt;

  &lt;dt&gt;Cascading Style Sheets (CSS)&lt;/dt&gt;
  &lt;dd&gt;Used to describe the appearance of Web content&lt;/dd&gt;

  &lt;dt&gt;JavaScript (JS)&lt;/dt&gt;
  &lt;dd&gt;The programming language used to build advanced Web sites and applications&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Integer posuere erat a ante venenatis dapibus posuere velit aliquet. Morbi leo risus, porta ac consectetur ac, vestibulum at eros. Nullam quis risus eget urna mollis ornare vel eu leo.&lt;/p&gt;

&lt;h3 id=&quot;images&quot;&gt;Images&lt;/h3&gt;

&lt;p&gt;Quisque consequat sapien eget quam rhoncus, sit amet laoreet diam tempus. Aliquam aliquam metus erat, a pulvinar turpis suscipit at.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://placehold.it/800x400&quot; alt=&quot;placeholder&quot; title=&quot;Large example image&quot; /&gt;
&lt;img src=&quot;https://placehold.it/400x200&quot; alt=&quot;placeholder&quot; title=&quot;Medium example image&quot; /&gt;
&lt;img src=&quot;https://placehold.it/200x200&quot; alt=&quot;placeholder&quot; title=&quot;Small example image&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;tables&quot;&gt;Tables&lt;/h3&gt;

&lt;p&gt;Aenean lacinia bibendum nulla sed consectetur. Lorem ipsum dolor sit amet, consectetur adipiscing elit.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;Upvotes&lt;/th&gt;
      &lt;th&gt;Downvotes&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tfoot&gt;
    &lt;tr&gt;
      &lt;td&gt;Totals&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tfoot&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Alice&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Bob&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Charlie&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Nullam id dolor id nibh ultricies vehicula ut id elit. Sed posuere consectetur est at lobortis. Nullam quis risus eget urna mollis ornare vel eu leo.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Want to see something else added? &lt;a href=&quot;https://github.com/poole/poole/issues/new&quot;&gt;Open an issue.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;equations&quot;&gt;Equations&lt;/h2&gt;

&lt;p&gt;Cum sociis natoque penatibus et magnis &lt;a href=&quot;#&quot;&gt;dis parturient montes&lt;/a&gt;, nascetur ridiculus mus. &lt;em&gt;Aenean eu leo quam.&lt;/em&gt; Pellentesque ornare sem lacinia quam venenatis vestibulum. Sed posuere consectetur est at lobortis. Cras mattis consectetur purus sit amet fermentum.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Curabitur blandit tempus porttitor. Nullam quis risus eget urna mollis ornare vel eu leo. Nullam id dolor id nibh ultricies vehicula ut id elit.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Etiam porta &lt;strong&gt;sem malesuada magna&lt;/strong&gt; mollis euismod. Cras mattis consectetur purus sit amet fermentum. Aenean lacinia bibendum nulla sed consectetur.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
  &amp; \phi(x,y) = \phi \left(\sum_{i=1}^n x_ie_i, \sum_{j=1}^n y_je_j \right)
  = \sum_{i=1}^n \sum_{j=1}^n x_i y_j \phi(e_i, e_j) = \\
  &amp; (x_1, \ldots, x_n) \left( \begin{array}{ccc}
      \phi(e_1, e_1) &amp; \cdots &amp; \phi(e_1, e_n) \\
      \vdots &amp; \ddots &amp; \vdots \\
      \phi(e_n, e_1) &amp; \cdots &amp; \phi(e_n, e_n)
    \end{array} \right)
  \left( \begin{array}{c}
      y_1 \\
      \vdots \\
      y_n
    \end{array} \right)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;side-by-side-images&quot;&gt;Side by side Images&lt;/h2&gt;

&lt;p&gt;&lt;img align=&quot;left&quot; src=&quot;/images/blog/optfuture/Eval.png&quot; alt=&quot;reacher&quot; style=&quot;width: 30%; margin:0px 10px; border-radius:0%&quot; /&gt;     &lt;img src=&quot;/images/blog/optfuture/Eval.png&quot; alt=&quot;reacher&quot; style=&quot;width: 30%; margin:0px 10px; border-radius:0%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;color-coded-text&quot;&gt;Color coded text&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/35465557/how-to-apply-color-in-markdown&quot;&gt;Stackoverflow page&lt;/a&gt; 
&lt;script type=&quot;math/tex&quot;&gt;\color{red}{\text{Red test 1}}&lt;/script&gt;&lt;/p&gt;

&lt;font color=&quot;red&quot;&gt;Red test 2&lt;/font&gt;

&lt;p&gt;&lt;em&gt;Red test 3&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong style=&quot;color: red; opacity: 0.80;&quot;&gt;My Bold Text, in red color.&lt;/strong&gt;&lt;/p&gt;</content><author><name>Yash Chandak</name></author><summary type="html">short summary</summary></entry></feed>